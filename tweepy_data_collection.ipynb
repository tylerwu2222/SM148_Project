{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"rs8fimR6iW9hQvLg45utLmdkF\" # REPLACE WITH OWN CONSUMER KEY AND SECRET\n",
    "consumer_secret = \"z19dkW6zpmzBICreE6C0XGCBLJlw64k7byRi58vHYLvzUEqrbi\"\n",
    "  \n",
    "# authorization of consumer key and consumer secret\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "# calling the api \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Notes:\n",
    "- User can be suspended, tweet could be deleted -> tweet ID returns error: Forbidden: 403 Forbidden\n",
    "63 - User has been suspended. -> need exception handling\n",
    "- Tweepy's `tweet.user.location` doesn't always return county level\n",
    "- other potential variables of interest: `description` (text of tweet), `followers_count` (to filter for most influential accounts?), `friends_count` (how many following), `created_at`, `id_str` (unique ID for user, could see who's tweeting about COVID the most)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection Notes:  \n",
    "\n",
    "0) Download txtcollector to combine csvs for each day into one for month: https://bluefive.pairsite.com/txtcollector.htm\n",
    "1) Download csvs for month using DownGit: https://downgit.github.io/#/home \n",
    "2) combine using txtcollector\n",
    "3) Run below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31011963"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweet_data/combinedapr2020.txt\") # <- change to correct file name\n",
    "total_tweets = len(df.index) # around 10 to 30 million tweets per month, maybe sample... 100,000? -> filter those for US, ~10,000 per month\n",
    "total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1254211431052034054, 1250172852227244032, 1246437946540032000, ...,\n",
       "       1247011731035095041, 1245724205309714433, 1255383327495905281],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from all tweets\n",
    "random.seed(1234)\n",
    "sample_size = 100000\n",
    "rand_tweets_indices = random.sample(range(0,total_tweets),sample_size)\n",
    "tweet_ids = df.iloc[:,0]\n",
    "tweet_id_sample = tweet_ids[rand_tweets_indices].values\n",
    "tweet_id_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter function for US states\n",
    "state_abbrs = [ 'AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
    "           'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY','USA','US']\n",
    "states = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \n",
    "            \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District of Columbia\",\n",
    "            \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \n",
    "            \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \n",
    "            \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \n",
    "            \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \n",
    "            \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \n",
    "            \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \n",
    "            \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \n",
    "            \"Wyoming\", \"United States\"]\n",
    "            \n",
    "def filter_location(location):\n",
    "    if ',' not in location:\n",
    "        return False\n",
    "    in_state_abbr = [re.search('^' + re.escape(state_abbr) + '|' + re.escape(state_abbr) + '$',location) for state_abbr in state_abbrs]\n",
    "    in_state = [re.search('^' + re.escape(state.lower()) + '|' + re.escape(state.lower()) + '$',location.lower()) for state in states]\n",
    "    return any(in_state_abbr + in_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# testing filter function\n",
    "print(filter_location('Portland, OR'))\n",
    "print(filter_location('Somewhere, India'))\n",
    "print(filter_location('USA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet 0 ; 0.0 pct done\n",
      "nah \n",
      "nah Richmond, VA 23231\n",
      "Pomona, CA\n",
      "nah \n",
      "nah ketterdam\n",
      "nah Newarthill,Lanarkshire\n",
      "nah \n",
      "nah Pale blue dot üåè\n",
      "nah \n",
      "Santa Barbara, CA\n",
      "California, USA\n",
      "nah London\n",
      "nah United States\n",
      "nah Johannesburg, South Africa\n",
      "nah ‡§®‡§à ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä, ‡§≠‡§æ‡§∞‡§§\n"
     ]
    }
   ],
   "source": [
    "# loop through all tweets and filter\n",
    "all_rows = []\n",
    "columns = ['location','likes','text','date']\n",
    "\n",
    "for i,id in enumerate(tweet_id_sample):\n",
    "    # save to csv every 500 tweets scanned in case of failure\n",
    "    if i % 500 == 0:\n",
    "        print(\"tweet\",i, \";\",round(i/sample_size * 100,4), \"pct done\")\n",
    "        US_tweets = pd.DataFrame(all_rows,columns=columns)\n",
    "        US_tweets.to_csv('tweet_data/US_covid_tweets.csv',index=False) # change this to reflect year_month\n",
    "    \n",
    "    # get tweet from id\n",
    "    try:\n",
    "        status = api.get_status(id)\n",
    "        user = status.user\n",
    "        # only append if user location in US\n",
    "        locale = user.location\n",
    "        if filter_location(locale):\n",
    "            # if('mask' in status.text.lower()):\n",
    "            row=[user.location, user.favourites_count, status.text, user.created_at.strftime(\"%Y-%m-%d\")]\n",
    "            all_rows.append(row)\n",
    "    except: # usually tweet deleted or user suspended\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO RUN THIS AFTER ALL MONTHS COLLECTED\n",
    "# load existing csv\n",
    "# US_tweets = pd.read_csv('US_covid_tweets.csv')\n",
    "# print(len(US_tweets.index))\n",
    "# US_tweets.head()\n",
    "\n",
    "# append new one to existing\n",
    "\n",
    "# save as one big csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minnesota, USA</td>\n",
       "      <td>287188</td>\n",
       "      <td>RT @B52Malmet: CDC confirms second US case of ...</td>\n",
       "      <td>2020-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>822</td>\n",
       "      <td>RT @ReutersBiz: Coronavirus outbreak may disru...</td>\n",
       "      <td>2020-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California, USA</td>\n",
       "      <td>21186</td>\n",
       "      <td>#Russia has just closed border due to #Coronav...</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Swamp, DC</td>\n",
       "      <td>88859</td>\n",
       "      <td>RT @AP: BREAKING: Delta Air Lines and American...</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rockford, IL</td>\n",
       "      <td>480</td>\n",
       "      <td>China Lockdown Spreads To 33 Million People As...</td>\n",
       "      <td>2020-01-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           location   likes  \\\n",
       "0    Minnesota, USA  287188   \n",
       "4       Chicago, IL     822   \n",
       "5   California, USA   21186   \n",
       "9     The Swamp, DC   88859   \n",
       "13     Rockford, IL     480   \n",
       "\n",
       "                                                 text        date  \n",
       "0   RT @B52Malmet: CDC confirms second US case of ...  2020-01-24  \n",
       "4   RT @ReutersBiz: Coronavirus outbreak may disru...  2020-01-28  \n",
       "5   #Russia has just closed border due to #Coronav...  2020-01-30  \n",
       "9   RT @AP: BREAKING: Delta Air Lines and American...  2020-01-31  \n",
       "13  China Lockdown Spreads To 33 Million People As...  2020-01-24  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't need to run this; just correcting a mistake\n",
    "valid_locations = US_tweets['location'].apply(lambda x: filter_location(x))\n",
    "US_tweets = US_tweets.loc[valid_locations]\n",
    "print(len(US_tweets.index)) # end up with 5.7k tweets\n",
    "US_tweets.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16e3b9799879e24d92f4a6010a8e3548b08661ef551ca0704bdd958592137b13"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
